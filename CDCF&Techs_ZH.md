[中文版](./CDCF&Techs_ZH.md)，[English version](./CDCF&Techs_EN.md)

---

# 功能规范与技术选型说明书（CdCF）

## SRT字幕文件优化模块

### 1. 项目目标

本项目旨在自动优化从YouTube下载的英文SRT字幕文件。这些字幕通常由AI自动生成，存在语法错误、拼写错误、识别错误等问题。我们通过语法修复、关键词替换和语言清晰度提升，使字幕文本更准确、自然、易于阅读。

项目最终成果将为一个Python包，可通过`pip install srtCtl`进行安装，作为命令行工具或Python库使用。该包应具备专业性、可复用性，并支持版本控制。

### 2. 输入说明

- `.srt`格式的英文字幕文件，通常通过`yt-dlp`等工具从YouTube下载；
- 可选：包含视频标题、频道名、描述等元信息的JSON数据（用于上下文增强）；
- 用户可选择不同运行模式（如是否生成diff对比文件），并支持选择不同语言模型进行处理。

### 3. 输出说明

- `filename.corrected.srt`：经过优化后的英文字幕文件；
- `filename.diff.txt`：原始字幕与优化字幕的逐行对比文件，标注修改前后的内容。

### 4. 功能性需求

- 检测字幕中的错误，包括但不限于：
  - 语法错误；
  - 标点缺失或使用错误；
  - 单词误用（如将“foreign”错误地用于泛指）；
  - 语音识别造成的重复、乱码、时序错乱等问题；
- 对每处错误进行记录，包括：
  - 行号；
  - 原始文本；
  - 错误类型；

- 支持对比功能，生成diff文件，展示原文与修正内容；
- 支持批量处理多个SRT文件；
- 原始文件需保留；
- 输出文件集中保存在指定目录下。

### 5. 实施约束

- 所有代码须使用Python语言开发；
- 系统必须可在普通开发者笔记本上运行，优先支持CPU运行；
- 所选语言模型优先使用本地部署（无需API），仅在必要时允许连接外部API；

---

## 技术选型方案

为了实现本项目目标，且遵循“避免使用黑盒API”的约束条件，我们将采用模块化、可解释、兼容CPU的技术方案。系统将结合开源语言模型、规则检测方法以及自定义逻辑，对字幕内容进行结构化修复与优化。

我们将探索多个开源预训练语言模型（如Qwen2.5-1.8B、Mistral-7B、TinyLLaMA），并在真实字幕数据上进行效果评估。这些模型将根据准确率、流畅性、运行速度和资源消耗等指标进行对比，最终推荐适合不同用户场景的模型版本。

若时间与资源允许，我们还将构建一个小规模训练数据集（例如100条人工修正字幕），用于对基础模型进行LoRA微调；并通过量化（Quantization）技术使得模型在低资源环境下可部署运行。

最终系统将打包为pip可安装的Python命令行工具，支持单文件和批处理模式，能够输出优化后的字幕文件与对比日志文件，确保工具具备实用性与可维护性。

---

### 可选模型列表（评估范围）

- 开源预训练语言模型（如 Qwen2.5, Mistral 等）
- 自行微调的LoRA模型

---

### 技术栈与工具清单

#### 模型推理支持

- `transformers`（模型加载与运行）
- `accelerate`, `auto-gptq`, `gguf`（量化与加速）

#### 字幕处理

- `pysrt`, `srt`（字幕解析与写入）
- `ffmpeg`（可选：提取音频或元数据）

#### 规则检测与文本分析

- `spaCy`（句法分析、词性标注）
- `LanguageTool`（轻量级本地语法检查）

#### 命令行与包管理

- `typer`（构建CLI命令行工具）
- `setuptools`, `pyproject.toml`（打包）
- `logging`, `tqdm`（调试与进度显示）

#### Diff对比功能

- `difflib`（Python内建差异比较工具）
- `deepdiff`（结构化文本比对）

---

### 模型评估指标

| 指标名称       | 描述                                           |
| -------------- | ---------------------------------------------- |
| **准确率**     | 修正后的字幕是否能正确表达原意，纠正真实错误？ |
| **语言流畅性** | 修正后的句子是否语法通顺、读起来自然？         |
| **处理速度**   | 每个模型处理一个SRT文件所需的平均时间          |
| **资源占用**   | 模型是否能在8–16GB内存的CPU设备上顺利运行？    |
| **可解释性**   | 修正结果是否清晰可追踪，diff是否易于理解？     |

我们将使用统一的字幕测试集对各模型进行评估，并在报告中推荐适合不同设备和使用场景的模型选择方案。